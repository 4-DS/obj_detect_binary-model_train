{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22dd98-718d-409f-b62f-67b79e10c046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96134cc9-1284-4cf3-9907-fdaf7a3c16f5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "pipeline_params={\n",
    "}\n",
    "step_params={\n",
    "}\n",
    "substep_params={   \n",
    "    \"MAX_SIZE\"     : 640,\n",
    "    \"BATCH\"        : 8,\n",
    "    \"WORKERS\"      : 0,\n",
    "    \"SEED\"         : 42,\n",
    "    \"EPOCH_COUNT\"  : 5,\n",
    "    \"MODEL_NAME\"   : \"yolox_s\",\n",
    "    \"optimizer_lr\" : 0.001,\n",
    "    \"pretrain_weights\": \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_s_8x8_300e_coco/yolox_s_8x8_300e_coco_20211121_095711-4592a793.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383d50f-8470-4e98-923f-6e7242250f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, default_param_values, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params, **default_param_values(\"params/step_params.json\"))\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [ \n",
    "      { STEP_NAME: \"data_prep\", ENTITY_NAME: \"train_data\"}, # train dataset from data_prep step\n",
    "      { STEP_NAME: \"data_prep\", ENTITY_NAME: \"eval_data\"}, # eval dataset from data_prep step\n",
    "      { STEP_NAME: \"data_prep\", ENTITY_NAME: \"dataset_config\"} # datasets config from data_prep step\n",
    "    ],\n",
    "    tmp_outputs =\n",
    "    [\n",
    "        { ENTITY_NAME: \"train_eval_data\" }, # datasets for train and eval on next substep\n",
    "        { ENTITY_NAME: \"train_eval_config\" }, # datasets configurations\n",
    "        { ENTITY_NAME: \"pretrain_weights\" }, # pretrain weights\n",
    "        { ENTITY_NAME: \"yolox_obj_detector\"} # resulting detector files\n",
    "    ]\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a613f37-8d49-445e-b297-e83953216a87",
   "metadata": {},
   "source": [
    "![interface 1_configure_train.drawio](./imgs/1_configure_train.drawio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2f6ca-d09e-48ac-836c-16f83baba10b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os.path as osp\n",
    "import os\n",
    "from pathlib import Path\n",
    "logging.root.setLevel(substep_params.get('loggingLevel', 'INFO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa9795-e379-4e35-8535-0af8e89888fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinara.store import SinaraStore\n",
    "\n",
    "inputs = substep.inputs(step_name = \"data_prep\")\n",
    "tmp_outputs = substep.tmp_outputs()\n",
    "\n",
    "# LOAD Train Images\n",
    "SinaraStore.dearchive_store_files_to_tmp(store_path=inputs.train_data, tmp_dir=tmp_outputs.train_eval_data)\n",
    "# LOAD Valid Images\n",
    "SinaraStore.dearchive_store_files_to_tmp(store_path=inputs.eval_data, tmp_dir=tmp_outputs.train_eval_data)\n",
    "# copy config from previos step to outputs\n",
    "SinaraStore.dearchive_store_files_to_tmp(store_path=inputs.dataset_config, tmp_dir=tmp_outputs.train_eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e25b0-e38b-43ad-b720-b7c21546632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the version of libraries and checking the availability of the cuda kernel\n",
    "import torch\n",
    "print(f\"{torch.__version__=}\")\n",
    "\n",
    "assert torch.cuda.is_available(), f\"Cuda not available\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_id = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(device_id)\n",
    "    print(f\"{device_name=}\")\n",
    "    print(f\"{torch.cuda.device_count()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b7d9c-32b2-403c-a620-967befad5454",
   "metadata": {},
   "source": [
    "#### Load pretrain weights to directory of pretrain_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0f55e-b672-4641-b3bf-ca6c743232fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_outputs = substep.tmp_outputs()\n",
    "data_url = substep_params[\"pretrain_weights\"]\n",
    "pretrain_weights_path = osp.join(tmp_outputs.pretrain_weights, osp.basename(data_url))\n",
    " \n",
    "!wget {data_url} -O {pretrain_weights_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b12338-5a95-414d-a3a5-bb61093e7e96",
   "metadata": {},
   "source": [
    "#### Read config and append training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99747867-4049-41a7-92d6-660883259cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config_fn = os.path.join(tmp_outputs.train_eval_config, 'config.json')\n",
    "\n",
    "with open(config_fn) as f_id:\n",
    "    CONFIG = json.load(f_id)\n",
    "\n",
    "CONFIG['train_config_parameters'] = substep_params\n",
    "# Normalize RGB images with standard normalization factor mean-std imagenet\n",
    "CONFIG['train_config_parameters'][\"Normalize\"] = {'mean': [123.675, 116.28, 103.53],\n",
    "                                                  'std': [58.395, 57.12, 57.375],\n",
    "                                                  'to_rgb': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d18eb-0dce-40d1-915f-cdb114679c06",
   "metadata": {},
   "source": [
    "## Setting up the training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554338f3-0ea8-4bc8-93cd-08f51fc35c05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Initializing modules from mmdetection, mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a866d-f114-41e6-8ea7-01db55cdc0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "import mmcv\n",
    "from mmcv import Config, ConfigDict\n",
    "\n",
    "import mmdet\n",
    "from mmdet.apis import init_random_seed, set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import get_root_logger\n",
    "import mmcls.models\n",
    "\n",
    "print(f\"{mmcv.__version__=}\")\n",
    "print(f\"{mmdet.__version__=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593d7df-9e81-451c-a653-a3eed4d32f99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Defining basic variables from the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ebe19-39a8-4952-834f-765eb979b706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining basic variables from the config\n",
    "base_seed = substep_params['SEED']**2\n",
    "seed = init_random_seed(base_seed)\n",
    "set_random_seed(seed, deterministic=False)\n",
    "\n",
    "EPOCH_COUNT = substep_params['EPOCH_COUNT']\n",
    "BATCH       = substep_params['BATCH']\n",
    "WORKERS     = substep_params['WORKERS']\n",
    "\n",
    "MODEL_NAME   = substep_params['MODEL_NAME']\n",
    "optimizer_lr = substep_params['optimizer_lr']\n",
    "\n",
    "CHECKPOINT_INTERVAL = 10\n",
    "############################################\n",
    "PROJECT_FOLDER = tmp_outputs.yolox_obj_detector\n",
    "MAX_SIZE       = substep_params['MAX_SIZE']\n",
    "CLASSES        = CONFIG['CLASSES']\n",
    "CLASSES_COUNT  = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f103b86-4f24-494d-a97d-7dce1ecc03ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Setting up basic model training config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f620dbf-702b-4718-8f83-f6ccdb03b18d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_dir = osp.join(osp.dirname(mmdet.__file__), '.mim', 'configs')\n",
    "\n",
    "cfg_path = \"yolox/yolox_s_8x8_300e_coco.py\"\n",
    "\n",
    "cfg = Config.fromfile(osp.join(cfg_dir, cfg_path))\n",
    "\n",
    "cfg.evaluation = {'metric': ['bbox'], 'save_best' : 'bbox_mAP'}\n",
    "# cfg.evaluation = {'metric': ['segm'], 'save_best' : 'segm_mAP'}\n",
    "\n",
    "#### set and create directory for saving model\n",
    "cfg.work_dir = os.path.join(PROJECT_FOLDER, MODEL_NAME)\n",
    "os.makedirs(cfg.work_dir, exist_ok=True)\n",
    "\n",
    "cfg.img_size = MAX_SIZE\n",
    "cfg.model.bbox_head.num_classes = CLASSES_COUNT\n",
    "cfg.model.test_cfg.nms.iou_threshold=0.5\n",
    "\n",
    "#### Set pretain_weights\n",
    "cfg.load_from = pretrain_weights_path\n",
    "\n",
    "#### Set frozen backbone\n",
    "cfg.model.backbone.frozen_stages = 4\n",
    "\n",
    "workflow = [('train', 1), ('val', 1)]\n",
    "cfg.workflow = workflow\n",
    "\n",
    "cfg.img_norm_cfg = CONFIG['train_config_parameters'][\"Normalize\"]\n",
    "cfg.data_root = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352b5e0-3056-434e-8a19-2de2a3a69861",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Augmentation pipelines for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9362f-b402-4e42-b8d0-ef88f3a3f6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmdet.datasets import PIPELINES\n",
    "\n",
    "# registry augmenation - DataAsList\n",
    "try:\n",
    "    @PIPELINES.register_module()\n",
    "    class DataAsList:\n",
    "        def __call__(self, results):\n",
    "            aug_data_dict = {key: [val] for key, val in results.items()}\n",
    "            return aug_data_dict\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "cfg.img_scale = (MAX_SIZE, MAX_SIZE)\n",
    "dataset_type = 'CocoDataset'\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    {'type': 'LoadImageFromFile'},\n",
    "    {'type': 'LoadAnnotations', 'with_bbox': True},\n",
    "    {'type': 'Resize', 'img_scale' : (MAX_SIZE, MAX_SIZE), 'keep_ratio': False},\n",
    "    {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (4.0, 4.0)},\n",
    "    {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
    "    {'type': 'Pad', 'size_divisor':32},\n",
    "    {'type': 'Normalize', **cfg.img_norm_cfg},\n",
    "    {'type': 'DefaultFormatBundle'},\n",
    "    {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    {'type': 'LoadImageFromFile'},\n",
    "    {'type': 'Resize', 'img_scale' : (MAX_SIZE, MAX_SIZE), 'keep_ratio': False},\n",
    "    {'type': 'RandomFlip', 'flip_ratio': 0.0},\n",
    "    {'type': 'Pad', 'size_divisor':32},   \n",
    "    {'type': 'Normalize', **cfg.img_norm_cfg},\n",
    "    {'type': 'DefaultFormatBundle'},\n",
    "    {'type': 'Collect', 'keys': ['img']},\n",
    "    {'type': 'DataAsList'}\n",
    "]\n",
    "\n",
    "cfg.train_dataset = dict(\n",
    "        type='CocoDataset',\n",
    "        filter_empty_gt=False, # for empty transporter (wht obj)\n",
    "        img_prefix=tmp_outputs.train_eval_data,\n",
    "        ann_file=osp.join(tmp_outputs.train_eval_data, CONFIG[\"train_coco_annotation\"]), \n",
    "        pipeline=cfg.train_pipeline,\n",
    "        classes=CLASSES,\n",
    ")\n",
    "\n",
    "cfg.test_dataset = dict(\n",
    "        type='CocoDataset',\n",
    "        filter_empty_gt=False,\n",
    "        img_prefix=tmp_outputs.train_eval_data,\n",
    "        ann_file=osp.join(tmp_outputs.train_eval_data, CONFIG[\"val_coco_annotation\"]), \n",
    "        pipeline=cfg.test_pipeline,\n",
    "        classes=CLASSES,\n",
    ")\n",
    "\n",
    "data = dict(\n",
    "    samples_per_gpu=BATCH,\n",
    "    workers_per_gpu=WORKERS,\n",
    "    train=cfg.train_dataset, \n",
    "    val=cfg.test_dataset, \n",
    "    test=cfg.test_dataset\n",
    ")\n",
    "\n",
    "cfg['data'] = ConfigDict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed956be-0fea-48aa-9566-11a28b842250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Setting up the optimizer configuration for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6117c581-8ff5-457b-86df-5b402e8e9f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get count images of training dataset\n",
    "%%time\n",
    "\n",
    "import io, re\n",
    "with io.open(cfg.data.train['ann_file']) as fd:\n",
    "    train_dataset = fd.read()\n",
    "train_dataset = re.findall('file_name', train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a34320-ed8c-4067-abb5-753b440a0805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the optimizer configuration\n",
    "ITERS_IN_ONE_EPOCH = int(len(train_dataset) / BATCH)\n",
    "MAX_ITER = (ITERS_IN_ONE_EPOCH * EPOCH_COUNT) - 1\n",
    "print(f\"{ITERS_IN_ONE_EPOCH=}\")\n",
    "print(f\"{MAX_ITER=}\")\n",
    "\n",
    "cfg.num_last_epochs = 15\n",
    "\n",
    "cfg.optimizer = dict(type='Adam', lr=optimizer_lr)\n",
    "   \n",
    "cfg.optimizer_config = {} #dict(grad_clip=None)\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    # _delete_=True,\n",
    "    policy= 'CosineAnnealing', #'YOLOX',\n",
    "    warmup='linear',\n",
    "    warmup_ratio=0.001,\n",
    "    warmup_iters=int(MAX_ITER * 0.25), # 5 epoch\n",
    "    min_lr_ratio=1e-5)\n",
    "\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=EPOCH_COUNT)\n",
    "\n",
    "checkpoint_config = dict(interval=CHECKPOINT_INTERVAL)\n",
    "if CHECKPOINT_INTERVAL == -1:\n",
    "    checkpoint_config = None\n",
    "    \n",
    "log_config = dict(\n",
    "    interval=(BATCH*2) if (BATCH*2) < (ITERS_IN_ONE_EPOCH / 2) else (ITERS_IN_ONE_EPOCH // 2),\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook', ignore_last=False)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cfg.merge_from_dict({\n",
    "    \"os\" : None,\n",
    "    \"ITERS_IN_ONE_EPOCH\" : ITERS_IN_ONE_EPOCH,\n",
    "    \"MAX_ITER\" : MAX_ITER,\n",
    "    \"EPOCH_COUNT\" : EPOCH_COUNT,\n",
    "    \"data\" : data,\n",
    "    \"checkpoint_config\" : checkpoint_config,\n",
    "    \"log_level\" : logging.getLevelName(logging.root.level),    \n",
    "    \"log_config\" : log_config,\n",
    "    \"resume_from\": None,\n",
    "})\n",
    "\n",
    "cfg.auto_resume = True # resume from the latest checkpoint automatically\n",
    "\n",
    "if cfg.load_from is not None:\n",
    "    cfg.auto_resume = False\n",
    "\n",
    "cfg.gpu_ids = [torch.cuda.current_device()]\n",
    "cfg.device='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f2348-8e68-4bc5-8fa7-26efd4be87f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Saving the configured config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d722a-e426-4056-88e6-f5174752658e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump config\n",
    "config_file = osp.join(cfg.work_dir, \"last_cfg.py\")\n",
    "cfg.dump(file=config_file)\n",
    "\n",
    "CONFIG['config_file'] = config_file\n",
    "CONFIG['work_dir']    = cfg.work_dir\n",
    "\n",
    "with open(config_fn, 'w') as f_id:\n",
    "    json.dump(CONFIG, f_id, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
